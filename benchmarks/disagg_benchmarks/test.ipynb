{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "100"
      ]
     },
     "execution_count": 1,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "a = [458, 496, 490, 491, 488, 510, 491, 520, 498, 494, 486, 493, 484, 500, 505, 501, 516, 498, 513, 504, 504, 501, 490, 501, 497, 503, 501, 500, 495, 503, 497, 489, 514, 502, 500, 497, 497, 511, 522, 504, 493, 502, 492, 513, 489, 490, 495, 474, 505, 495, 492, 493, 502, 498, 500, 516, 505, 512, 510, 505, 516, 516, 507, 494, 483, 500, 478, 503, 497, 495, 492, 511, 520, 517, 488, 489, 510, 502, 503, 496, 495, 507, 514, 508, 497, 516, 506, 500, 509, 500, 494, 514, 488, 519, 505, 473, 507, 516, 501, 493]\n",
    "len(a)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import vllm\n",
    "from vllm import LLM, SamplingParams\n",
    "\n",
    "# 初始化模型\n",
    "llm = LLM(model='/root/models/Qwen/Qwen2.5-7B-Instruct-GPTQ-Int4')\n",
    "\n",
    "# 设置 prompt\n",
    "prompt = ['''\n",
    "请围绕“快拍”这一主题，详细阐述其定义、特点、应用场景、优势与劣势，并结合实际案例说明其在现代生活中的重要性。快拍（Snapchat）是一种以“阅后即焚”为核心的社交媒体平台，其独特的瞬时性、娱乐性和互动性吸引了大量用户。请从以下几个方面展开回答：\n",
    "\n",
    "定义与功能：快拍是什么？它的核心功能有哪些？\n",
    "用户群体：快拍的主要用户是哪些人？为什么他们喜欢使用快拍？\n",
    "特点与创新：快拍与传统社交媒体平台相比有哪些独特之处？\n",
    "应用场景：快拍在日常生活中是如何被使用的？例如，朋友之间的即时分享、品牌营销、新闻传播等。\n",
    "优势与劣势：快拍的优势是什么？它有哪些潜在的不足或风险？\n",
    "社会影响：快拍对现代社会的文化、社交方式以及信息传播产生了哪些影响？\n",
    "技术实现：快拍背后的技术是如何支持其核心功能的？例如，如何实现“阅后即焚”？\n",
    "未来发展趋势：快拍在未来可能会如何发展？它是否能够持续吸引用户？\n",
    "请以清晰、逻辑性强的方式进行回答，结合具体数据和案例，以便更好地理解快拍的价值和意义。例如，可以提到快拍在疫情期间如何被用于传播信息，或者它在年轻用户中的流行程度。此外，可以分析快拍在某些领域的成功应用，如品牌如何通过快拍与年轻消费者建立联系，以及快拍在新闻传播中的即时性优势。最后，请总结快拍对社交媒体生态的影响，并对其未来发展提出合理预测。''', \n",
    "        #   \"你是谁\"\n",
    "          ]*1\n",
    "\n",
    "# 设置采样参数，设置 max_tokens=1 以便只生成一个 token\n",
    "sampling_params = SamplingParams(temperature=0.7, top_p=0.9, max_tokens=300) #  max_tokens=2\n",
    "\n",
    "# 进行 prefill\n",
    "outputs = llm.generate(prompt, sampling_params)\n",
    "# 0.056 0.041\n",
    "# 输出 prefill 阶段的结果\n",
    "for output in outputs:\n",
    "    print(f\"Generated text: {output.outputs[0].text}\")\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 75,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.0004572868347167969\n"
     ]
    }
   ],
   "source": [
    "import torch\n",
    "a = torch.randn((512,)).cuda(0)\n",
    "b = torch.ones_like(a,dtype=bool).cuda(0)\n",
    "b[2] = False\n",
    "import time\n",
    "t = time.time()\n",
    "a = a[b]\n",
    "print(time.time() - t)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 88,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.0004851818084716797\n"
     ]
    }
   ],
   "source": [
    "b = a.clone()\n",
    "t = time.time()\n",
    "torch.allclose(b,a)\n",
    "print(time.time() - t)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "13123213\n",
      "['asddddddddddddddddddddddddddd']\n",
      "['asddddddddddddddddddddddddddd']\n",
      "3.14\n"
     ]
    }
   ],
   "source": [
    "from multiprocessing import Process, Value, Array\n",
    "\n",
    "class t:\n",
    "    def __init__(self):\n",
    "        self.g = 13233\n",
    "\n",
    "    def aa(self):\n",
    "        print(13123213)\n",
    "        print(self.g)\n",
    "        self.g = 9999999\n",
    "        \n",
    "    def modify_values(self,num_array, num_value):\n",
    "        num_array[0] = 3.14\n",
    "        num_value.value = 2.71\n",
    "        self.g = ['asddddddddddddddddddddddddddd']\n",
    "        p = Process(target=self.aa)\n",
    "        p.start()\n",
    "        p.join()\n",
    "        print(self.g)\n",
    "\n",
    "\n",
    "if __name__ == \"__main__\":\n",
    "    num_array = Array('d', [0.0])\n",
    "    num_value = Value('d', 0.0)\n",
    "    a = 1000\n",
    "    tt = t()\n",
    "    p = Process(target=tt.modify_values, args=(num_array, num_value))\n",
    "    p.start()\n",
    "    p.join()\n",
    "\n",
    "    print(num_array[0])  # 输出: 3.14"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2\n"
     ]
    }
   ],
   "source": [
    "import queue\n",
    "\n",
    "from pyparsing import deque\n",
    "\n",
    "\n",
    "a = queue.Queue()\n",
    "a.put(1)\n",
    "a.put(2)\n",
    "b = a.get()\n",
    "a.put(b)\n",
    "print(a.queue[0])\n",
    "\n",
    "b = deque()\n",
    "a.queue.extend([12])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "b = a.queue\n",
    "b.popleft()\n",
    "a.queue\n",
    "c = [1,2,3,4]\n",
    "a.queue.extend(c)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "import threading\n",
    "import time\n",
    "import torch\n",
    "\n",
    "class test:\n",
    "    def __init__(self):\n",
    "        self.x = 10\n",
    "        self.l = []\n",
    "        self.r = []\n",
    "        self.a = torch.cuda.Stream()\n",
    "        self.b = torch.cuda.Stream()\n",
    "        self.aa = 0\n",
    "        with torch.cuda.stream(self.a):\n",
    "            self.thread_work = threading.Thread(target=self.test_step)\n",
    "            self.thread_work.start()\n",
    "\n",
    "        # with torch.cuda.stream(self.b):\n",
    "        #     self.thread_work1 = threading.Thread(target=self.run)\n",
    "        #     self.thread_work1.start()\n",
    "        \n",
    "        # self.thread_work1.join()\n",
    "        # self.thread_work.join()\n",
    "\n",
    "\n",
    "        \n",
    "    def test_step(self):\n",
    "        while len(self.l)<30:\n",
    "            # time.sleep(2)\n",
    "            self.step(True)\n",
    "\n",
    "    def run(self):\n",
    "        n = 0\n",
    "  \n",
    "        time.sleep(2)\n",
    "        self.step()\n",
    "        # while len(self.l)<20:\n",
    "        #     continue\n",
    "        # while n <self.x:\n",
    "        #     n += 1\n",
    "        #     self.step()\n",
    "            # time.sleep(0.5)\n",
    "\n",
    "    def step(self,flag=False):\n",
    "        self.aa += int(flag) * 10\n",
    "        if not flag:\n",
    "            print(self.aa)\n",
    "        if flag:\n",
    "            for i in range(self.x):\n",
    "                self.l.append(i)\n",
    "        else:\n",
    "            print(self.l)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "deque([12, 1])"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from queue import deque\n",
    "a = deque()\n",
    "a.append(12)\n",
    "a.append(1)\n",
    "a"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "ename": "TypeError",
     "evalue": "'int' object is not iterable",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mTypeError\u001b[0m                                 Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[4], line 3\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;21;01mqueue\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;28;01mimport\u001b[39;00m deque\n\u001b[1;32m      2\u001b[0m a \u001b[38;5;241m=\u001b[39m deque()\n\u001b[0;32m----> 3\u001b[0m \u001b[43ma\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mextend\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m12\u001b[39;49m\u001b[43m)\u001b[49m\n\u001b[1;32m      4\u001b[0m a\u001b[38;5;241m.\u001b[39mextend(\u001b[38;5;241m1\u001b[39m)\n\u001b[1;32m      5\u001b[0m a\n",
      "\u001b[0;31mTypeError\u001b[0m: 'int' object is not iterable"
     ]
    }
   ],
   "source": [
    "from queue import deque\n",
    "a = deque()\n",
    "a.extend()\n",
    "a.extend(1)\n",
    "a"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor(12132.)\n",
      "tensor(1.)\n"
     ]
    }
   ],
   "source": [
    "import torch\n",
    "import multiprocessing # type: ignore\n",
    "a = torch.ones((4,5000,3))\n",
    "def aass():\n",
    "    a[0][0][0] = 12132\n",
    "    print(a[0][0][0])\n",
    "p1 = multiprocessing.Process(target=aass)\n",
    "p1.start()\n",
    "p1.join()\n",
    "print(a[0][0][0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/root/miniconda3/envs/latest/lib/python3.10/site-packages/pygments/regexopt.py:77: RuntimeWarning: coroutine 'main' was never awaited\n",
      "  '|'.join(regex_opt_inner(list(group[1]), '')\n",
      "RuntimeWarning: Enable tracemalloc to get the object allocation traceback\n"
     ]
    },
    {
     "ename": "NameError",
     "evalue": "name 'time' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[2], line 24\u001b[0m\n\u001b[1;32m     21\u001b[0m     \u001b[38;5;28mprint\u001b[39m(\u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mfinished at \u001b[39m\u001b[38;5;132;01m{\u001b[39;00mtime\u001b[38;5;241m.\u001b[39mstrftime(\u001b[38;5;124m'\u001b[39m\u001b[38;5;132;01m%X\u001b[39;00m\u001b[38;5;124m'\u001b[39m)\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m\"\u001b[39m)\n\u001b[1;32m     23\u001b[0m \u001b[38;5;66;03m# 运行主函数\u001b[39;00m\n\u001b[0;32m---> 24\u001b[0m \u001b[43mmain\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n",
      "Cell \u001b[0;32mIn[2], line 15\u001b[0m, in \u001b[0;36mmain\u001b[0;34m()\u001b[0m\n\u001b[1;32m      9\u001b[0m task1 \u001b[38;5;241m=\u001b[39m asyncio\u001b[38;5;241m.\u001b[39mcreate_task(\n\u001b[1;32m     10\u001b[0m     say_after(\u001b[38;5;241m2\u001b[39m, \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mhello\u001b[39m\u001b[38;5;124m'\u001b[39m))\n\u001b[1;32m     12\u001b[0m task2 \u001b[38;5;241m=\u001b[39m asyncio\u001b[38;5;241m.\u001b[39mcreate_task(\n\u001b[1;32m     13\u001b[0m     say_after(\u001b[38;5;241m1\u001b[39m, \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mworld\u001b[39m\u001b[38;5;124m'\u001b[39m))\n\u001b[0;32m---> 15\u001b[0m \u001b[38;5;28mprint\u001b[39m(\u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mstarted at \u001b[39m\u001b[38;5;132;01m{\u001b[39;00m\u001b[43mtime\u001b[49m\u001b[38;5;241m.\u001b[39mstrftime(\u001b[38;5;124m'\u001b[39m\u001b[38;5;132;01m%X\u001b[39;00m\u001b[38;5;124m'\u001b[39m)\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m\"\u001b[39m)\n\u001b[1;32m     17\u001b[0m \u001b[38;5;66;03m# 等待两个任务都完成\u001b[39;00m\n\u001b[1;32m     18\u001b[0m a \u001b[38;5;241m=\u001b[39m [task1,task2]\n",
      "\u001b[0;31mNameError\u001b[0m: name 'time' is not defined"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "world\n",
      "hello\n"
     ]
    }
   ],
   "source": [
    "import asyncio\n",
    "\n",
    "async def say_after(delay, what):\n",
    "    await asyncio.sleep(delay)\n",
    "    print(what)\n",
    "\n",
    "def main():\n",
    "    # 创建两个任务\n",
    "    task1 = asyncio.create_task(\n",
    "        say_after(2, 'hello'))\n",
    "\n",
    "    task2 = asyncio.create_task(\n",
    "        say_after(1, 'world'))\n",
    "\n",
    "    print(f\"started at {time.strftime('%X')}\")\n",
    "\n",
    "    # 等待两个任务都完成\n",
    "    a = [task1,task2]\n",
    "    asyncio.gather(*a)\n",
    "\n",
    "    print(f\"finished at {time.strftime('%X')}\")\n",
    "\n",
    "# 运行主函数\n",
    "main()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 238,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.001440286636352539\n"
     ]
    },
    {
     "ename": "",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31mThe Kernel crashed while executing code in the current cell or a previous cell. \n",
      "\u001b[1;31mPlease review the code in the cell(s) to identify a possible cause of the failure. \n",
      "\u001b[1;31mClick <a href='https://aka.ms/vscodeJupyterKernelCrash'>here</a> for more info. \n",
      "\u001b[1;31mView Jupyter <a href='command:jupyter.viewOutput'>log</a> for further details."
     ]
    }
   ],
   "source": [
    "import torch\n",
    "import time\n",
    "def t1():\n",
    "    tensor = torch.randn(20000, 20000, device='cuda')\n",
    "    result = tensor @ tensor  # 矩阵乘法\n",
    "    return 1\n",
    "stream_a = torch.cuda.Stream()\n",
    "a = time.time()\n",
    "# with torch.cuda.stream(stream_a):\n",
    "#     t1()\n",
    "# print(time.time()-a)\n",
    "# stream_b = torch.cuda.Stream()\n",
    "# with torch.cuda.stream(stream_b):\n",
    "#     t1()\n",
    "g = t1()\n",
    "g = t1()\n",
    "print(time.time()-a)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "deque([1, 2, 3])"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "ename": "",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31mThe Kernel crashed while executing code in the current cell or a previous cell. \n",
      "\u001b[1;31mPlease review the code in the cell(s) to identify a possible cause of the failure. \n",
      "\u001b[1;31mClick <a href='https://aka.ms/vscodeJupyterKernelCrash'>here</a> for more info. \n",
      "\u001b[1;31mView Jupyter <a href='command:jupyter.viewOutput'>log</a> for further details."
     ]
    }
   ],
   "source": [
    "from queue import deque\n",
    "a = deque([1,2,3,4])\n",
    "b = a\n",
    "b.pop()\n",
    "a"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(1, deque(['da']))"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "def remove_elements(lst, indices):\n",
    "    # 按降序排序索引，避免因删除操作导致索引变动\n",
    "    for index in sorted(indices, reverse=True):\n",
    "        lst.pop(index)\n",
    "    return lst\n",
    "\n",
    "a = [11,2,31,4,5]\n",
    "remove_elements(a,[2,3])\n",
    "from queue import Queue\n",
    "a = Queue()\n",
    "a.put('da')\n",
    "a.qsize(),a.queue\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "class OutputData(NamedTuple):\n",
    "    outputs = []\n",
    "    seq_group_metadata_list = []\n",
    "    is_async: bool"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from torch import multiprocessing\n",
    "import torch\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "系统共有 128 个CPU核心\n"
     ]
    }
   ],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "latest",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.16"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
